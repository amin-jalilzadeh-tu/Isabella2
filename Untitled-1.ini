your_project/
│
├── data/
│   └── (raw CSV files, if any)
│
├── models/
│   └── (trained model checkpoints, e.g., .pt files)
│
├── scalers/
│   └── (saved scikit-learn joblib files)
│
├── utils/
│   ├── carbon.py
│   ├── cost.py
│   └── (other utility scripts)
│
├── src/
│   ├── data_preprocessing.py
│   ├── model_definitions.py
│   ├── training_functions.py
│   ├── evaluation_functions.py
│   ├── training_pipeline.py
│   ├── evaluation_pipeline.py
│   ├── inference_pipeline.py       
│   ├── optimization_pipeline.py   
│   ├── mcdm_pipeline.py          
│   ├── postprocessing_pipeline.py   

├── main.py
├── streamlit_app.py
├── requirements.txt
└── README.md



from src.training_pipeline import train_models_if_needed

def main():
    # Suppose we have train_loader, val_loader, X_data_normalized, scalers_Y, etc.
    train_models_if_needed(
        X_data_normalized=X_data_normalized,
        scalers_Y=scalers_Y,
        scaler_X=scaler_X,
        train_loader=train_loader,
        val_loader=val_loader,
        do_training=True,  # set to False if you want to skip training
        num_epochs=50,
        learning_rate=1e-4,
        weights=[1.0, 1.0, 1.0, 1.0]
    )

if __name__ == "__main__":
    main()
